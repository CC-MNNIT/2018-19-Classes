{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "object classification.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "YAyGJkhpo23g"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CC-MNNIT/2018-19-Classes/blob/master/MachineLearning/2019_04_11_ML3_content/object_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "vkgRvs85pq32",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Copyright 2019 MNNIT Computer Club."
      ]
    },
    {
      "metadata": {
        "id": "y8Nv6gMHpUsM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8KQLIfZfpXor",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "> Reading someone else's code is more important than writing your own."
      ]
    },
    {
      "metadata": {
        "id": "n6XmGPOopx8F",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Before we begin"
      ]
    },
    {
      "metadata": {
        "id": "neDHUZ44WH2Z",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Install kaggle API\n",
        "!pip install -q kaggle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DAncsu6ZVzf7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "1. Go to your kaggle account page\n",
        "2. click ```Create New API Token```\n",
        "3. A json file shall be downloaded to your system\n",
        "4. Run the following cell, and upload that json file"
      ]
    },
    {
      "metadata": {
        "id": "fMUfa2MSaD-6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Please accept the competition rules before proceeding** since we will be using their dataset\n",
        "\n",
        "[Competition rules : cats and dogs](https://www.kaggle.com/c/dogs-vs-cats/rules)"
      ]
    },
    {
      "metadata": {
        "id": "9HAFh_CTp8Uo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## A few driver functions\n",
        "\n",
        "I have written a few functions, which can be used on colab to save your time. Since they solve a repetitve task."
      ]
    },
    {
      "metadata": {
        "id": "gR6N2ddXemrb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def download_extract_colab(API_string, reupload_JSON=False, json_filename=\"/content/kaggle.json\"):\n",
        "    \n",
        "    # TODO: \n",
        "    # improve ls output at the end, distinguish between files and directories, preferably linux ls -al like output\n",
        "    # Add doc string\n",
        "    # add more comments\n",
        "    \n",
        "    \n",
        "    import os,shutil,sys  \n",
        "            \n",
        "    if not os.path.exists(os.path.expanduser(\"~/.kaggle/kaggle.json\")) or reupload_JSON == True:\n",
        "        \n",
        "        from google.colab import files\n",
        "        \n",
        "        print(\"Please upload your kaggle API file...\")\n",
        "        files.upload()\n",
        "\n",
        "        if not os.path.exists(os.path.expanduser(\"~/.kaggle/\")):\n",
        "            os.mkdir(os.path.expanduser(\"~/.kaggle/\"))\n",
        "\n",
        "        os.rename(json_filename,os.path.expanduser(\"~/.kaggle/kaggle.json\"))\n",
        "        os.chmod(os.path.expanduser(\"~/.kaggle/kaggle.json\"),600)\n",
        "    \n",
        "    \n",
        "    \n",
        "    if os.path.exists(\"/content/dataset\"):\n",
        "        shutil.rmtree(\"/content/dataset\")\n",
        "    os.mkdir(\"/content/dataset\")\n",
        "    \n",
        "\n",
        "    sys.stdout.write(\"Downloading the dataset...\")\n",
        "    # download the dataset\n",
        "    os.system(API_string+\" -p /content/dataset/\")\n",
        "    sys.stdout.write(\"Done!\\n\")\n",
        "    \n",
        "\n",
        "    # extract the zip files into dataset folder\n",
        "    sys.stdout.write(\"Extracting the dataset...\")\n",
        "    os.system(\"unzip '/content/dataset/*.zip' -d /content/dataset/; rm /content/dataset/*.zip\")\n",
        "    sys.stdout.write(\"Done!\\n\")\n",
        "    \n",
        "    print(\"===================\")\n",
        "    print(\"Dataset files downloaded at /content/dataset :\")\n",
        "    for file in os.listdir(\"/content/dataset\"):\n",
        "        print(\"\\t/content/dataset/\",file)\n",
        "    print(\"===================\")\n",
        "    \n",
        "    return \"/content/dataset\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EPP4EnO7qYjb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# the following function can be saved, since it will be extensively reused\n",
        "\n",
        "def plot_loss_acc(history):\n",
        "    \n",
        "    import matplotlib.pyplot as plt\n",
        "    \n",
        "    acc = history.history['acc']\n",
        "    val_acc = history.history['val_acc']\n",
        "    \n",
        "    loss = history.history['loss']\n",
        "    val_loss = history.history['val_loss']\n",
        "    \n",
        "    epochs = range(1, len(acc) + 1)\n",
        "    \n",
        "    \n",
        "    plt.plot(epochs, acc, 'bo', label='Training acc')\n",
        "    plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
        "    plt.title('Training and validation accuracy')\n",
        "    plt.legend()\n",
        "    plt.figure()\n",
        "\n",
        "    plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "    plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "    plt.title('Training and validation loss')\n",
        "    plt.legend()\n",
        "    \n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "drTJ48e8ces4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Let's begin"
      ]
    },
    {
      "metadata": {
        "id": "AVK1ub57dG-h",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Download Data"
      ]
    },
    {
      "metadata": {
        "id": "iF7KnL5feV9n",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os,shutil"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0GVYZeO5igqU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "original_dataset_dir = download_extract_colab(\"kaggle competitions download -c dogs-vs-cats\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YAyGJkhpo23g",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Create a proper folder structure to store the data\n",
        "\n",
        "Since it's a binary object classification problem. \n",
        "- we can exploit the [flow_from_directory method](https://keras.io/preprocessing/image/#flow_from_directory) of keras.\n",
        "- The method requires that the data is organised as follows:\n",
        "    - data\n",
        "        - dogs\n",
        "        - cats\n",
        "- i.e the data directory should contain one subdirectory per class.\n",
        "- So, all the dog images under a directory named dogs (and similarly for cats) we can save ourselves the hassle of manually creating batches."
      ]
    },
    {
      "metadata": {
        "id": "aZpTF5YOiMIb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# audit how the dataset looks like and read the documentation about the dataset from kaggle\n",
        "\n",
        "os.listdir(os.path.join(original_dataset_dir,\"train\"))\n",
        "# os.listdir(os.path.join(original_dataset_dir,\"test1\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SP9oNkGmhS-l",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# directories where we store data after preprocessing (if any)\n",
        "base_dir = \"/content/project\"\n",
        "os.mkdir(base_dir)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# training directories\n",
        "train_dir = os.path.join(base_dir,\"train\")\n",
        "os.mkdir(train_dir)\n",
        "\n",
        "train_dogs_dir = os.path.join(train_dir,\"dogs\")\n",
        "os.mkdir(train_dogs_dir)\n",
        "\n",
        "train_cats_dir = os.path.join(train_dir,\"cats\")\n",
        "os.mkdir(train_cats_dir)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# validation directories\n",
        "validation_dir = os.path.join(base_dir,\"validation\")\n",
        "os.mkdir(validation_dir)\n",
        "\n",
        "validation_dogs_dir = os.path.join(validation_dir,\"dogs\")\n",
        "os.mkdir(validation_dogs_dir)\n",
        "\n",
        "validation_cats_dir = os.path.join(validation_dir,\"cats\")\n",
        "os.mkdir(validation_cats_dir)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# testing directories\n",
        "test_dir = os.path.join(base_dir,\"test\")\n",
        "os.mkdir(test_dir)\n",
        "\n",
        "test_dogs_dir = os.path.join(test_dir,\"dogs\")\n",
        "os.mkdir(test_dogs_dir)\n",
        "\n",
        "test_cats_dir = os.path.join(test_dir,\"cats\")\n",
        "os.mkdir(test_cats_dir)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "83Y3rR1vdBzu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Populate Empty Directories"
      ]
    },
    {
      "metadata": {
        "id": "LF6Vs0QElj35",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# populate the empty cat directories\n",
        "\n",
        "\n",
        "fnames = ['cat.{}.jpg'.format(i) for i in range(1000)]\n",
        "for cat in fnames:\n",
        "    src = os.path.join(original_dataset_dir,\"train\",cat)\n",
        "    dst = os.path.join(train_cats_dir,cat)\n",
        "    shutil.copyfile(src,dst)    \n",
        "    \n",
        "\n",
        "fnames = ['cat.{}.jpg'.format(i) for i in range(1000,1500)]\n",
        "for cat in fnames:\n",
        "    src = os.path.join(original_dataset_dir,\"train\",cat)\n",
        "    dst = os.path.join(validation_cats_dir,cat)\n",
        "    shutil.copyfile(src,dst)\n",
        "    \n",
        "\n",
        "fnames = ['cat.{}.jpg'.format(i) for i in range(1500,2000)]\n",
        "for cat in fnames:\n",
        "    src = os.path.join(original_dataset_dir,\"train\",cat)\n",
        "    dst = os.path.join(test_cats_dir,cat)\n",
        "    shutil.copyfile(src,dst)\n",
        "    \n",
        "\n",
        "# populate the empty dog directories\n",
        "\n",
        "\n",
        "fnames = ['dog.{}.jpg'.format(i) for i in range(1000)]\n",
        "for dog in fnames:\n",
        "    src = os.path.join(original_dataset_dir,\"train\",dog)\n",
        "    dst = os.path.join(train_dogs_dir,dog)\n",
        "    shutil.copyfile(src,dst)    \n",
        "\n",
        "fnames = ['dog.{}.jpg'.format(i) for i in range(1000,1500)]\n",
        "for dog in fnames:\n",
        "    src = os.path.join(original_dataset_dir,\"train\",dog)\n",
        "    dst = os.path.join(validation_dogs_dir,dog)\n",
        "    shutil.copyfile(src,dst)    \n",
        "    \n",
        "\n",
        "fnames = ['dog.{}.jpg'.format(i) for i in range(1500,2000)]\n",
        "for dog in fnames:\n",
        "    src = os.path.join(original_dataset_dir,\"train\",dog)\n",
        "    dst = os.path.join(test_dogs_dir,dog)\n",
        "    shutil.copyfile(src,dst)    \n",
        "\n",
        "    \n",
        "# len(os.listdir(test_dogs_dir))    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wuPi045UqBiK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Build a keras model"
      ]
    },
    {
      "metadata": {
        "id": "dgTv9ls7sUsk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### FIRST : define datagenerators\n",
        "\n",
        "Since we are dealing with image data, it would be preferable if we could create data generators which could automatically create batches of images (and additionally perform data augmentation) and supply that to the fit_generator method of a keras model."
      ]
    },
    {
      "metadata": {
        "id": "KcQIY_DPxUa0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=40,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True)\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_gen = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(150,150),\n",
        "    batch_size=20,\n",
        "    class_mode='binary')\n",
        "\n",
        "validation_gen = test_datagen.flow_from_directory(\n",
        "    validation_dir,\n",
        "    target_size=(150,150),\n",
        "    batch_size=20,\n",
        "    class_mode='binary')\n",
        "\n",
        "test_gen = test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=(150,150),\n",
        "    batch_size=20,\n",
        "    class_mode='binary')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-b-HvfFVc4DO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### From Scratch (baseline model)"
      ]
    },
    {
      "metadata": {
        "id": "zoH8qFu0eVPL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras import layers\n",
        "from keras.utils import plot_model\n",
        "\n",
        "from keras import backend as K"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KA1dUxmWeWGx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# to reset the tf graph\n",
        "K.clear_session()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZHU0WUd9py_A",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add( layers.Conv2D(32,(3,3),activation='relu', input_shape=(150,150,3)) )\n",
        "model.add( layers.MaxPooling2D((2,2)))\n",
        "\n",
        "model.add( layers.Conv2D(64,(3,3),activation='relu' ))\n",
        "model.add( layers.MaxPooling2D((2,2)))\n",
        "\n",
        "model.add( layers.Conv2D(128,(3,3),activation='relu' ))\n",
        "model.add( layers.MaxPooling2D((2,2)))\n",
        "          \n",
        "model.add( layers.Conv2D(128,(3,3),activation='relu' ))\n",
        "model.add( layers.MaxPooling2D((2,2)))\n",
        "          \n",
        "# model.add( layers.Conv2D(224,(3,3),activation='relu' ))\n",
        "# model.add( layers.MaxPooling2D((2,2)))\n",
        "\n",
        "model.add( layers.Flatten() )\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add( layers.Dense(512,activation='relu'))\n",
        "# sigmoid since our classification problem is binary -> 0 - dogs, 1 - cats\n",
        "model.add( layers.Dense(1,activation='sigmoid'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lbmPOPX_tvpf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0lnQPXpsuTGF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from IPython.display import Image\n",
        "plot_model(model,show_shapes=True,show_layer_names=True,to_file=\"baseline_model.png\",rankdir='TB')\n",
        "Image(retina=True, filename='baseline_model.png')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YyDQHa0pwfF2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='rmsprop',loss='binary_crossentropy',metrics=['acc'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XC9L4U2_yTFq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "history = model.fit_generator(\n",
        "    train_gen,\n",
        "    steps_per_epoch=100,\n",
        "    epochs=100,\n",
        "    validation_data=validation_gen,\n",
        "    validation_steps=50\n",
        "    )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6pHMHprdzo0Z",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.save(\"cats_dog_1.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AwHd8wL11TG1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plot_loss_acc(history)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "n9tI1rd_efGL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Using Transfer learning (very practical)\n"
      ]
    },
    {
      "metadata": {
        "id": "tbih7oYfpG5S",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "- Use a pre-trained model (a CNN). \n",
        "- Since CNNs learn low level patterns(eg. edges, curves etc) in their initial layers, we can freeze the initial layers and allow the model only to adjust the weights of the later layers (which learn high level features such as a cat or a dog).\n",
        "\n",
        "---\n",
        "To understand transfer learning : view a CNN model as\n",
        ">>>>>> Convolution base + Classifier (= Last Dense layer/Linear Model)\n",
        "---\n",
        "\n",
        "There are two ways transfer learning can be used :\n",
        "\n",
        "1. Feature Extraction :\n",
        "    - Freeze all but the last layer (Dense) :\n",
        "        - view the last dense layer as a perceptron model mimicing a linear model\n",
        "        - it can be replaced via any other classifier (eg. a decision tree)\n",
        "    - Use the convolution base as it is (since it has already learnt lower level representations on a bigger dataset)\n",
        "        - the output of the conv base are basically just extracted features.\n",
        "        - The weights of this convolution base are LOCKED. So that they don't change during the training process\n",
        "    - Train this model on your dataset. Only the weights of the last layer are allowed to change, which learn the higher level features of the problem.\n",
        "    - Test the model\n",
        "2. Fine Tuning\n",
        "    - Freeze all but the last FEW layers (Dense and some convolutional layers)\n",
        "    "
      ]
    },
    {
      "metadata": {
        "id": "x4Km4SQeeLb3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Feature Extraction"
      ]
    },
    {
      "metadata": {
        "id": "4qNlOzAFelIV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras import layers\n",
        "from keras.utils import plot_model\n",
        "\n",
        "from keras.applications.vgg16 import VGG16"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZhZX5itwePhI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Use VGG16 with imagenet weights as the convolution base"
      ]
    },
    {
      "metadata": {
        "id": "TeXXQJv0lc4j",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# include_top=False -> do not include the Dense layer of the VGG16 network\n",
        "conv_base = VGG16(include_top=False,\n",
        "                  weights=\"imagenet\",\n",
        "                  input_shape=(150,150,3))\n",
        "\n",
        "# Since all the layers are yet not freezed\n",
        "# their weights will be changed upon training\n",
        "# so let's freeze the conv base\n",
        "conv_base.trainable = False\n",
        "conv_base.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "D7qTsMJ0ef31",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Create a CNN model\n",
        "- Use the locked VGG16 CNN without it's dense layer as the conv base.\n",
        "- Add your own Dense Layer (Classifier) at the end"
      ]
    },
    {
      "metadata": {
        "id": "MXZxvQYfq-Gr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "t_model = Sequential()\n",
        "\n",
        "t_model.add( conv_base )\n",
        "t_model.add( layers.Flatten() )\n",
        "t_model.add( layers.Dense(256,activation='relu') )\n",
        "t_model.add( layers.Dense(1,activation='sigmoid') )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2iCmdXLWrxBB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "t_model.compile(optimizer='rmsprop',\n",
        "                loss='binary_crossentropy',\n",
        "                metrics=['acc'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "a2L0UyUJrbfR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "t_model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZKymTKo9rckn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "history = t_model.fit_generator(train_gen,\n",
        "                                steps_per_epoch=100,\n",
        "                                epochs=30,\n",
        "                                validation_data=validation_gen,\n",
        "                                validation_steps=50\n",
        "                               )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bi5C5YiBrugT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plot_loss_acc(history)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zsCPwqMjwDI0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "t_model.save(\"transfer_learned_model_cats_dogs.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "52wOw_T_flJ2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Visualise Results"
      ]
    },
    {
      "metadata": {
        "id": "2dMv7XYgS8iB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.preprocessing import image\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5HI1f1t4bXfj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# draw a batch of test images from the test generator\n",
        "imgs,labels = next(test_gen)\n",
        "\n",
        "# make predictions on this batch\n",
        "predictions = t_model.predict_classes(imgs,batch_size=test_gen.batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "R7BZyLEZmGuI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# convert the integer(0/1) class labels to original strings -> dog, cat\n",
        "\n",
        "rev_map = { v:k[:-1] for k,v in test_gen.class_indices.items() }\n",
        "predictions = [rev_map[i[0]] for i in predictions]\n",
        "labels = [rev_map[i] for i in labels.astype('int')]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pl1k112LLDuH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "row = col = 4\n",
        "\n",
        "fig,all_ax = plt.subplots(row,col,figsize=(20,20))\n",
        "\n",
        "for i in range(len(all_ax)):\n",
        "    for j,ax in enumerate(all_ax[i]):\n",
        "        \n",
        "        curr_idx = len(all_ax)*i+j\n",
        "        \n",
        "        ax.imshow(imgs[curr_idx])\n",
        "        ax.set_title( \"Prediction:\"+predictions[curr_idx]+\" | Actual:\"+labels[curr_idx])\n",
        "        ax.axis('off')\n",
        "        ax.grid(False)\n",
        "    \n",
        "plt.show()\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "P6JSnTNofwhy",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "####### Redundant code\n",
        "\n",
        "# # download the dataset\n",
        "# !kaggle competitions download -c dogs-vs-cats -p dataset/\n",
        "\n",
        "# # extract the zip files into dataset folder\n",
        "# !unzip 'dataset/*.zip' -d dataset/\n",
        "# !rm dataset/*.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dJFO0_i-hpQI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "Authored By [Dipunj Gupta](https://github.com/dipunj) | Report errors/typos as github issues.\n",
        "\n",
        "---"
      ]
    }
  ]
}